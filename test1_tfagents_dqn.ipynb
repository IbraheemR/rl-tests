{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "import reverb\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import gym\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 20000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration = 1 # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 1000  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}\n",
    "save_interval = 5000  # @param {type:\"integer\"}\n",
    "\n",
    "fc_layer_params = (100, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env():\n",
    "\n",
    "    env = gym.make('CartPole-v1')\n",
    "    return suite_gym.wrap_env(env)\n",
    "\n",
    "env = get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=600x400>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate sample image\n",
    "\n",
    "env.reset()\n",
    "PIL.Image.fromarray(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Spec:\n",
      "BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])\n",
      "Reward Spec:\n",
      "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n",
      "Action Spec:\n",
      "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=1)\n"
     ]
    }
   ],
   "source": [
    "print('Observation Spec:')\n",
    "print(env.time_step_spec().observation)\n",
    "print('Reward Spec:')\n",
    "print(env.time_step_spec().reward)\n",
    "print('Action Spec:')\n",
    "print(env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([-0.01264504,  0.02047336, -0.00818995, -0.04241277], dtype=float32),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(0, dtype=int32)})\n",
      "Next time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([-0.01223557,  0.21571179, -0.00903821, -0.33766842], dtype=float32),\n",
      " 'reward': array(1., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n"
     ]
    }
   ],
   "source": [
    "time_step = env.reset()\n",
    "print('Time step:')\n",
    "print(time_step)\n",
    "\n",
    "action = np.array(1, dtype=np.int32)\n",
    "\n",
    "next_time_step = env.step(action)\n",
    "print('Next time step:')\n",
    "print(next_time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Env setup\n",
    "\n",
    "train_py_env = get_env()\n",
    "eval_py_env = get_env()\n",
    "\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct network.\n",
    "\n",
    "# fc_layer_params = (100, 50) # Moved to paramters section\n",
    "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "# Define a helper function to create Dense layers configured with the right\n",
    "# activation and kernel initializer.\n",
    "def dense_layer(num_units):\n",
    "  return tf.keras.layers.Dense(\n",
    "      num_units,\n",
    "      activation=tf.keras.activations.relu,\n",
    "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
    "# with `num_actions` units to generate one q_value per available action as\n",
    "# its output.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 19:47:37.255200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-29 19:47:37.259624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-29 19:47:37.259856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-29 19:47:37.260632: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-29 19:47:37.261132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-29 19:47:37.261308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-29 19:47:37.261461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-29 19:47:37.649586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-29 19:47:37.649782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-29 19:47:37.649938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-29 19:47:37.650072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4389 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:26:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "## Agent & Optimiser definition\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()\n",
    "\n",
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## avg return profiling\n",
    "\n",
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random policy benchmark\n",
    "\n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())\n",
    "\n",
    "example_environment = tf_py_environment.TFPyEnvironment(\n",
    "    get_env()\n",
    ")\n",
    "\n",
    "time_step = example_environment.reset()\n",
    "random_policy.action(time_step)\n",
    "\n",
    "random_policy_baseline = compute_avg_return(eval_env, random_policy, num_eval_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/platform/tfrecord_checkpointer.cc:162]  Initializing TFRecordCheckpointer in /tmp/tmpe1xwmt4y.\n",
      "[reverb/cc/platform/tfrecord_checkpointer.cc:552] Loading latest checkpoint from /tmp/tmpe1xwmt4y\n",
      "[reverb/cc/platform/default/server.cc:71] Started replay server on port 43649\n"
     ]
    }
   ],
   "source": [
    "## Replay Buffer\n",
    "\n",
    "table_name = 'uniform_table'\n",
    "replay_buffer_signature = tensor_spec.from_spec(\n",
    "      agent.collect_data_spec)\n",
    "replay_buffer_signature = tensor_spec.add_outer_dim(\n",
    "    replay_buffer_signature)\n",
    "\n",
    "table = reverb.Table(\n",
    "    table_name,\n",
    "    max_size=replay_buffer_max_length,\n",
    "    sampler=reverb.selectors.Uniform(),\n",
    "    remover=reverb.selectors.Fifo(),\n",
    "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
    "    signature=replay_buffer_signature)\n",
    "\n",
    "reverb_server = reverb.Server([table])\n",
    "\n",
    "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    table_name=table_name,\n",
    "    sequence_length=2,\n",
    "    local_server=reverb_server)\n",
    "\n",
    "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
    "  replay_buffer.py_client,\n",
    "  table_name,\n",
    "  sequence_length=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TimeStep(\n",
       " {'discount': array(1., dtype=float32),\n",
       "  'observation': array([ 0.02047994,  0.38307327, -0.07202084, -0.90301305], dtype=float32),\n",
       "  'reward': array(1., dtype=float32),\n",
       "  'step_type': array(1, dtype=int32)}),\n",
       " ())"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PyDriver\n",
    "\n",
    "py_driver.PyDriver(\n",
    "    env,\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "      random_policy, use_tf_function=True),\n",
    "    [rb_observer],\n",
    "    max_steps=initial_collect_steps).run(train_py_env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset from Replay Buffer\n",
    "\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3,\n",
    "    sample_batch_size=batch_size,\n",
    "    num_steps=2).prefetch(3)\n",
    "\n",
    "dataset\n",
    "\n",
    "iterator = iter(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Video output\n",
    "\n",
    "def embed_mp4(filename):\n",
    "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "  video = open(filename,'rb').read()\n",
    "  b64 = base64.b64encode(video)\n",
    "  tag = '''\n",
    "  <video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "  </video>'''.format(b64.decode())\n",
    "\n",
    "  return IPython.display.HTML(tag)\n",
    "\n",
    "def create_policy_eval_video(policy, filename, num_episodes=5, fps=30):\n",
    "  time_step = eval_env.reset()\n",
    "  first_frame = eval_py_env.render()\n",
    "  blank_frame = np.zeros_like(first_frame)\n",
    "  blank_frame[:,:,0] = 255 # magenta\n",
    "\n",
    "  filename = \"videos/\" + filename + \".mp4\"\n",
    "  with imageio.get_writer(filename, fps=fps) as video:\n",
    "    for _ in range(num_episodes):\n",
    "      time_step = eval_env.reset()\n",
    "      video.append_data(eval_py_env.render())\n",
    "      while not time_step.is_last():\n",
    "        action_step = policy.action(time_step)\n",
    "        time_step = eval_env.step(action_step.action)\n",
    "        video.append_data(eval_py_env.render())\n",
    "\n",
    "      # write 1 second of black frames between each episode  \n",
    "      for i in range(fps): \n",
    "        video.append_data(blank_frame)\n",
    "  return embed_mp4(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/zsh: /home/ibraheem/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /usr/bin/zsh)\n",
      "/usr/bin/zsh: /home/ibraheem/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /usr/bin/zsh)\n"
     ]
    }
   ],
   "source": [
    "# Clean video folder\n",
    "\n",
    "!rm -rf videos\n",
    "!mkdir videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (400, 600) to (400, 608) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to None (risking incompatibility). You may also see a FFMPEG warning concerning speedloss due to data not being aligned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model video at step 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[swscaler @ 0x55b3c147c9c0] Warning: data is not aligned! This can lead to a speed loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ibraheem/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (25936) so Table uniform_table is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (25936) so Table uniform_table is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (25936) so Table uniform_table is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (25936) so Table uniform_table is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (25936) so Table uniform_table is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:165] Sampler and server are owned by the same process (25936) so Table uniform_table is accessed directly without gRPC.\n",
      "WARNING:tensorflow:From /home/ibraheem/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 1000: loss = 116.34452819824219\n",
      "step = 1000: Average Return = 498.79998779296875\n",
      "step = 2000: loss = 2648.21728515625\n",
      "step = 2000: Average Return = 201.10000610351562\n",
      "step = 3000: loss = 571.65625\n",
      "step = 3000: Average Return = 127.30000305175781\n",
      "step = 4000: loss = 18283.01953125\n",
      "step = 4000: Average Return = 114.4000015258789\n",
      "step = 5000: loss = 1807.302001953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (400, 600) to (400, 608) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to None (risking incompatibility). You may also see a FFMPEG warning concerning speedloss due to data not being aligned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5000: Average Return = 139.39999389648438\n",
      "Saving model video at step 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[swscaler @ 0x5578305859c0] Warning: data is not aligned! This can lead to a speed loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6000: loss = 4162.3994140625\n",
      "step = 6000: Average Return = 174.1999969482422\n",
      "step = 7000: loss = 1584.6224365234375\n",
      "step = 7000: Average Return = 230.0\n",
      "step = 8000: loss = 34165.9765625\n",
      "step = 8000: Average Return = 500.0\n",
      "step = 9000: loss = 119636.109375\n",
      "step = 9000: Average Return = 500.0\n",
      "step = 10000: loss = 198690.359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (400, 600) to (400, 608) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to None (risking incompatibility). You may also see a FFMPEG warning concerning speedloss due to data not being aligned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 10000: Average Return = 500.0\n",
      "Saving model video at step 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[swscaler @ 0x55fb636169c0] Warning: data is not aligned! This can lead to a speed loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 11000: loss = 96864.9609375\n",
      "step = 11000: Average Return = 500.0\n",
      "step = 12000: loss = 186674.75\n",
      "step = 12000: Average Return = 500.0\n",
      "step = 13000: loss = 891335.6875\n",
      "step = 13000: Average Return = 500.0\n",
      "step = 14000: loss = 337029.375\n",
      "step = 14000: Average Return = 500.0\n",
      "step = 15000: loss = 495254.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (400, 600) to (400, 608) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to None (risking incompatibility). You may also see a FFMPEG warning concerning speedloss due to data not being aligned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 15000: Average Return = 500.0\n",
      "Saving model video at step 15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[swscaler @ 0x55ee5dc759c0] Warning: data is not aligned! This can lead to a speed loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 16000: loss = 4502247.0\n",
      "step = 16000: Average Return = 496.70001220703125\n",
      "step = 17000: loss = 690549.0\n",
      "step = 17000: Average Return = 500.0\n",
      "step = 18000: loss = 156832.953125\n",
      "step = 18000: Average Return = 484.20001220703125\n",
      "step = 19000: loss = 52378068.0\n",
      "step = 19000: Average Return = 497.20001220703125\n",
      "step = 20000: loss = 56118580.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (400, 600) to (400, 608) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to None (risking incompatibility). You may also see a FFMPEG warning concerning speedloss due to data not being aligned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 20000: Average Return = 487.29998779296875\n",
      "Saving model video at step 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[swscaler @ 0x5567d60ab9c0] Warning: data is not aligned! This can lead to a speed loss\n"
     ]
    }
   ],
   "source": [
    "## Training loop\n",
    "\n",
    "try:\n",
    "  %%time\n",
    "except:\n",
    "  pass\n",
    "\n",
    "videos = []\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step.\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "# Reset the environment.\n",
    "time_step = train_py_env.reset()\n",
    "\n",
    "# Create a driver to collect experience.\n",
    "collect_driver = py_driver.PyDriver(\n",
    "    env,\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "      agent.collect_policy, use_tf_function=True),\n",
    "    [rb_observer],\n",
    "    max_steps=collect_steps_per_iteration)\n",
    "\n",
    "print(f'Saving model video at step 0')\n",
    "create_policy_eval_video(agent.policy, f\"trained-agent-0\")\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps and save to the replay buffer.\n",
    "  time_step, _ = collect_driver.run(time_step)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = agent.train(experience).loss\n",
    "\n",
    "  step = agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)\n",
    "\n",
    "  if step % save_interval == 0:\n",
    "    print(f'Saving model video at step {step}')\n",
    "    create_policy_eval_video(agent.policy, f\"trained-agent-{step}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iterations')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.axhline(random_policy_baseline, color='red')\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8497aef48dcb678f741e8b3bb7d0dad5584c781895c0fcce04e242f8c3de41db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
